{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNaMQDLIiE3aPmvvLORavk9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachit2005/UNET-/blob/main/unet_using_snn_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YwJt2k4L8Zou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe72b4f-36fe-490c-8ea2-0e5ffb59acdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'carotid-ultrasound-images' dataset.\n",
            "Path to dataset files: /kaggle/input/carotid-ultrasound-images\n",
            "Using Colab cache for faster access to the 'carotid-ultrasound-images' dataset.\n",
            "Path to dataset files: /kaggle/input/carotid-ultrasound-images\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"orvile/carotid-ultrasound-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "!pip install snntorch\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "zUMsWSFmBB26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c148d4-f535-4f6c-bf95-3cf4fcb0f90f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.12/dist-packages (0.9.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.12/dist-packages (0.9.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d orvile/carotid-ultrasound-images"
      ],
      "metadata": {
        "id": "n8hmy7NfBJFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c4f9c8-ae05-4ac8-d059-e1ffb8a6e2bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/orvile/carotid-ultrasound-images\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "carotid-ultrasound-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip carotid-ultrasound-images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M-IQ2bfoBLXz",
        "outputId": "0d1b31d6-d036-43ea-a22f-304bca6e82a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  carotid-ultrasound-images.zip\n",
            "replace Common Carotid Artery Ultrasound Images/Common Carotid Artery Ultrasound Images/Expert mask images/202201121748100022VAS_slice_1069.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "base_path = \"Common Carotid Artery Ultrasound Images/Common Carotid Artery Ultrasound Images/\"\n",
        "mask_path = base_path + \"Expert mask images\"\n",
        "image_path = base_path + \"US images\"\n",
        "\n",
        "print(f\"total len: {len(os.listdir(image_path))}\")\n",
        "print(f\"sample images: {os.listdir(image_path)[:5]}\")"
      ],
      "metadata": {
        "id": "F2UJzHmvBkZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TTZz8j8oAYt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_files = sorted([os.path.join(image_path, file) for file in os.listdir(image_path)])\n",
        "masks_files = sorted([os.path.join(mask_path, file) for file in os.listdir(mask_path)])"
      ],
      "metadata": {
        "id": "7a5IpyNVBBS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"image\":images_files , \"mask\":masks_files})\n",
        "\n",
        "print(len(df))\n",
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "wgxFVvNmCvln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "image_size = 256\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size , image_size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class UNETDataset(Dataset):\n",
        "    def __init__(self , df , transform=transform):\n",
        "      self.df = df\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      image = self.df.iloc[index , 0]\n",
        "      mask = self.df.iloc[index , 0]\n",
        "\n",
        "      image = Image.open(image).convert(\"RGB\")\n",
        "      mask = Image.open(mask).convert(\"L\")\n",
        "\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "        mask = self.transform(mask)\n",
        "\n",
        "      return image , mask"
      ],
      "metadata": {
        "id": "wOfefYOCAuwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = UNETDataset(df)\n",
        "\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3FnIS6CPFKns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet Model"
      ],
      "metadata": {
        "id": "3l1SYXeWGx15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from snntorch import surrogate\n",
        "import snntorch as snn\n",
        "\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self , in_channels , out_channels , beta=0.9):\n",
        "    super().__init__()\n",
        "\n",
        "    spike_grad = surrogate.atan()\n",
        "\n",
        "    self.conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels , out_channels=out_channels , kernel_size=3 , padding=1),\n",
        "        snn.Leaky(beta=beta, spike_grad=spike_grad , init_hidden=True),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(in_channels=out_channels , out_channels=out_channels , kernel_size=3 , padding=1),\n",
        "        snn.Leaky(beta=beta, spike_grad=spike_grad , init_hidden=True),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.conv_layer(x)\n",
        "\n",
        "  def reset_state(self):\n",
        "        \"\"\"Resets the membrane potential (state) of the internal neurons.\"\"\"\n",
        "        for layer in self.conv_layer:\n",
        "            if isinstance(layer, snn.Leaky):\n",
        "                layer.reset_hidden()\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self , in_channels , out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_block = conv_block(in_channels , out_channels)\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2 , stride=2)\n",
        "\n",
        "  def forward(self , x):\n",
        "    x_skip = self.conv_block(x)\n",
        "    p = self.max_pool(x_skip)\n",
        "    return x_skip , p\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.conv_block.reset_state()\n",
        "\n",
        "# we will add the x to the decoder output to improve the accuracy and to follow the unet paper\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self , in_channels , out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.up_conv = nn.ConvTranspose2d(in_channels=in_channels , out_channels=out_channels , kernel_size=2 , stride=2)\n",
        "    self.conv_block = conv_block(out_channels*2 , out_channels)\n",
        "\n",
        "  def forward(self , x , skip_connections):\n",
        "    x = self.up_conv(x)\n",
        "    x = torch.cat([x , skip_connections] , dim=1)\n",
        "    return self.conv_block(x)\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.conv_block.reset_state()\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Encoder\n",
        "    self.encoder1 = Encoder(3 , 64)\n",
        "    self.encoder2 = Encoder(64 , 128)\n",
        "    self.encoder3 = Encoder(128 , 256)\n",
        "    self.encoder4 = Encoder(256 , 512)\n",
        "\n",
        "    # bottle neck\n",
        "    self.bottle_neck = conv_block(512 , 1024)\n",
        "\n",
        "    # Decoder\n",
        "    self.decoder1 = Decoder(1024 , 512)\n",
        "    self.decoder2 = Decoder(512 , 256)\n",
        "    self.decoder3 = Decoder(256, 128)\n",
        "    self.decoder4 = Decoder(128 , 64)\n",
        "\n",
        "    self.final = nn.Conv2d(64 , 1 , kernel_size=1)\n",
        "\n",
        "\n",
        "  def forward(self , x):\n",
        "    x1 , p1 = self.encoder1(x)\n",
        "    x2 , p2 = self.encoder2(p1)\n",
        "    x3 , p3 = self.encoder3(p2)\n",
        "    x4 , p4 = self.encoder4(p3)\n",
        "\n",
        "    x = self.bottle_neck(p4)\n",
        "\n",
        "    d1 = self.decoder1(x , x4)\n",
        "    d2 = self.decoder2(d1,x3)\n",
        "    d3 = self.decoder3(d2,x2)\n",
        "    d4 = self.decoder4(d3,x1)\n",
        "\n",
        "    return self.final(d4)\n",
        "\n",
        "\n",
        "  def reset_state(self):\n",
        "      \"\"\"\n",
        "      Resets all membrane potentials across the entire network.\n",
        "      CRITICAL for SNNs, typically called at the start of a new batch/sequence.\n",
        "      \"\"\"\n",
        "      self.encoder1.reset_state()\n",
        "      self.encoder2.reset_state()\n",
        "      self.encoder3.reset_state()\n",
        "      self.encoder4.reset_state()\n",
        "      self.bottle_neck.reset_state()\n",
        "      self.decoder4.reset_state()\n",
        "      self.decoder3.reset_state()\n",
        "      self.decoder2.reset_state()\n",
        "      self.decoder1.reset_state()"
      ],
      "metadata": {
        "id": "AlZoCq7-FUrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET()\n",
        "x = torch.randn((1,3,512,512))\n",
        "y = model(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "4lf6D8-fPcbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 32\n",
        "learning_rate = 3e-4\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters() , lr=learning_rate)"
      ],
      "metadata": {
        "id": "6S4kiBg2GKpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset , batch_size , shuffle=True)\n",
        "images , masks = next(iter(train_loader))\n",
        "print(images.shape , masks.shape)"
      ],
      "metadata": {
        "id": "YrYz_4PzGRX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_hist = []\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "\n",
        "  for batch , (images , masks) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    masks = masks.to(device)\n",
        "\n",
        "    model.reset_state()\n",
        "    output_masks = model(images)\n",
        "\n",
        "    loss = loss_fn(output_masks , masks)\n",
        "\n",
        "    loss_hist.append(loss)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"epoch: {epoch} | loss: {loss} | batch: {batch}\")"
      ],
      "metadata": {
        "id": "Ql5aCl5dHNDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USold-tiJ-9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hpt2lUYnGyHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}